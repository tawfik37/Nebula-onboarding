# Nebula - AI Onboarding Assistant

[![CI](https://github.com/tawfik37/Nebula-onboarding/actions/workflows/ci.yml/badge.svg)](https://github.com/tawfik37/Nebula-onboarding/actions)
[![Python 3.10](https://img.shields.io/badge/python-3.10-blue.svg)](https://www.python.org/downloads/)

An **Agentic RAG system** that helps new hires navigate company policies, org structure, and role-specific requirements. Built with LangGraph, FastAPI, and Streamlit.

## Highlights

- **ReAct Agent** â€” Reasons over multiple tools before answering (not a simple prompt chain)
- **Streaming + Reasoning UI** â€” Watch the agent think in real-time: tool calls, results, and final answer
- **Smart Ingestion** â€” Incremental vector ingestion with MD5 change detection (no re-processing unchanged files)
- **Persistent Memory** â€” SQLite-backed conversation history survives backend restarts
- **Docker Ready** â€” `docker-compose up` spins up the full stack
- **CI Pipeline** â€” Ruff linting + 23 unit tests on every push

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Streamlit Frontend          â”‚
â”‚   Chat UI  Â·  Agent Reasoning Panel  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ SSE Stream
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          FastAPI Backend             â”‚
â”‚  /api/v1/chat/stream  Â·  /health    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     LangGraph ReAct Agent            â”‚
â”‚     (Gemini 2.5 Flash, temp=0)       â”‚
â”‚                                      â”‚
â”‚  Tools:                              â”‚
â”‚  ðŸ” search_policies  â†’ ChromaDB     â”‚
â”‚  ðŸ‘¤ lookup_employee   â†’ org_chart    â”‚
â”‚  ðŸ“‹ lookup_role_reqs  â†’ role_defs   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Tech Stack

| Layer | Technology |
|-------|-----------|
| LLM | Google Gemini 2.5 Flash |
| Agent Framework | LangGraph (ReAct pattern) |
| Vector Store | ChromaDB with Gemini Embeddings |
| Backend | FastAPI + Uvicorn |
| Frontend | Streamlit |
| Memory | SQLite (langgraph-checkpoint-sqlite) |
| CI | GitHub Actions (ruff + pytest) |

## Quick Start

### Option 1: Docker (Recommended)

```bash
# Clone and configure
git clone https://github.com/tawfik37/Nebula-onboarding.git
cd Nebula-onboarding
cp .env.example .env  # Add your GOOGLE_API_KEY

# Run
docker-compose up --build
```

- Frontend: http://localhost:8501
- API: http://localhost:8000
- Health: http://localhost:8000/health

### Option 2: Local

```bash
# Initialize
chmod +x scripts/init.sh
./scripts/init.sh

# Add your API key
echo "GOOGLE_API_KEY=your-key-here" > .env

# Run
./scripts/run_app.sh
```

## API Endpoints

| Method | Path | Description |
|--------|------|-------------|
| `GET` | `/` | Root status check |
| `GET` | `/health` | Detailed health (DB doc count, data file status) |
| `POST` | `/api/v1/chat` | Synchronous chat (JSON response) |
| `POST` | `/api/v1/chat/stream` | Streaming chat (SSE with tool events) |

## Project Structure

```
Nebula-onboarding/
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ main.py              # FastAPI endpoints + SSE streaming
â”‚       â””â”€â”€ models/schemas.py    # Pydantic request/response models
â”œâ”€â”€ rag_engine/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ onboarding_agent.py  # LangGraph ReAct agent setup
â”‚   â”‚   â””â”€â”€ tools.py             # 3 agent tools (policies, employees, roles)
â”‚   â””â”€â”€ ingestion/
â”‚       â””â”€â”€ ingest.py            # Incremental vector ingestion pipeline
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py                   # Streamlit chat UI with reasoning panel
â”œâ”€â”€ data_seed/
â”‚   â”œâ”€â”€ policies/                # Markdown policy documents
â”‚   â””â”€â”€ structured/              # JSON org chart + role definitions
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ test_tools.py            # Unit tests for tools + schemas
â”‚   â”œâ”€â”€ test_ingestion.py        # Unit tests for ingestion pipeline
â”‚   â””â”€â”€ test_api.py              # Integration tests (requires running server)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ init.sh                  # Project initialization
â”‚   â””â”€â”€ run_app.sh               # Start backend + frontend
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ ruff.toml
```

## Running Tests

```bash
# Unit tests (no server needed)
pytest test/test_tools.py test/test_ingestion.py -v

# Integration tests (requires running backend)
./scripts/run_app.sh &
pytest test/test_api.py -v
```

## Knowledge Base

The system ingests two types of data:

**Unstructured (Vector Search):**
- `HR_001_Employee_Handbook.md` â€” PTO, stipends, core hours, communication
- `IT_002_Information_Security_Policy.md` â€” Passwords, MFA, data classification, prohibited software

**Structured (JSON Lookup):**
- `org_chart.json` â€” 6 employees with IDs, titles, managers, locations
- `role_definitions.json` â€” 3 roles with required tools, permissions, first-week goals

## License

MIT
